{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import sys\n",
    "import pts.dataset\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # If using multi-GPU.\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set your desired seed\n",
    "set_seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.dataset.multivariate_grouper import MultivariateGrouper\n",
    "#import gluonts.torch.distributions.distribution_output\n",
    "from gluonts.dataset.repository.datasets import dataset_recipes, get_dataset\n",
    "from pts.model.tempflow import TempFlowEstimator\n",
    "from pts.model.transformer_tempflow import TransformerTempFlowEstimator\n",
    "from pts import Trainer\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.evaluation import MultivariateEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepeare data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset(\"exchange_rate_nips\", regenerate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_grouper = MultivariateGrouper(max_target_dim=int(dataset.metadata.feat_static_cat[0].cardinality))\n",
    "\n",
    "test_grouper = MultivariateGrouper(num_test_dates=int(len(dataset.test)/len(dataset.train)), \n",
    "                                   max_target_dim=int(dataset.metadata.feat_static_cat[0].cardinality))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = train_grouper(dataset.train)\n",
    "dataset_test = test_grouper(dataset.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MultivariateEvaluator(quantiles=(np.arange(20)/20.0)[1:],\n",
    "                                  target_agg_funcs={'sum': np.sum})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `GRU-Real-NVP`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TempFlowEstimator(\n",
    "    target_dim=int(dataset.metadata.feat_static_cat[0].cardinality),\n",
    "    prediction_length=dataset.metadata.prediction_length,\n",
    "    cell_type='GRU',\n",
    "    input_size=28,\n",
    "    freq=dataset.metadata.freq,\n",
    "    scaling=True,\n",
    "    dequantize=True,\n",
    "    n_blocks=7,\n",
    "    trainer=Trainer(device=device,\n",
    "                    epochs=40,\n",
    "                    learning_rate=0.01,\n",
    "                    num_batches_per_epoch=100,\n",
    "                    batch_size=64)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = estimator.train(dataset_train, num_workers=4)\n",
    "forecast_it, ts_it = make_evaluation_predictions(dataset=dataset_test,\n",
    "                                             predictor=predictor,\n",
    "                                             num_samples=100)\n",
    "forecasts = list(forecast_it)\n",
    "targets = list(ts_it)\n",
    "\n",
    "agg_metric, _ = evaluator(targets, forecasts, num_series=len(dataset_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_nll = 0.0\n",
    "count = 0\n",
    "\n",
    "for forecast, target in zip(forecasts, targets):\n",
    "    # Compute mean and std from the forecast samples\n",
    "    mu = forecast.samples.mean(axis=0)  # Mean of the samples\n",
    "    sigma = forecast.samples.std(axis=0)  # Standard deviation of the samples\n",
    "\n",
    "    # Align target to match the forecast's prediction length\n",
    "    target = np.array(target[-forecast.samples.shape[1]:])  # Take the last `prediction_length` values\n",
    "\n",
    "    if target.shape != mu.shape:\n",
    "        print(f\"Shape mismatch after alignment: target {target.shape}, forecast {mu.shape}\")\n",
    "        continue\n",
    "\n",
    "    # Compute NLL for this time series\n",
    "    nll = -torch.distributions.Normal(\n",
    "        torch.tensor(mu), torch.tensor(sigma)\n",
    "    ).log_prob(torch.tensor(target)).sum().item()\n",
    "\n",
    "    total_nll += nll\n",
    "    count += target.size  # Number of data points\n",
    "\n",
    "# Compute mean NLL\n",
    "if count > 0:\n",
    "    mean_nll = total_nll / count\n",
    "    print(f\"Mean NLL on Test Set: {mean_nll}\")\n",
    "else:\n",
    "    print(\"No valid data points for NLL calculation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CRPS: {}\".format(agg_metric['mean_wQuantileLoss']))\n",
    "print(\"ND: {}\".format(agg_metric['ND']))\n",
    "print(\"NRMSE: {}\".format(agg_metric['NRMSE']))\n",
    "print(\"MSE: {}\".format(agg_metric['MSE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CRPS-Sum: {}\".format(agg_metric['m_sum_mean_wQuantileLoss']))\n",
    "print(\"ND-Sum: {}\".format(agg_metric['m_sum_ND']))\n",
    "print(\"NRMSE-Sum: {}\".format(agg_metric['m_sum_NRMSE']))\n",
    "print(\"MSE-Sum: {}\".format(agg_metric['m_sum_MSE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"REALNVP_DONE##########################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `GRU-MAF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TempFlowEstimator(\n",
    "    target_dim=int(dataset.metadata.feat_static_cat[0].cardinality),\n",
    "    prediction_length=dataset.metadata.prediction_length,\n",
    "    cell_type='GRU',\n",
    "    input_size=28,\n",
    "    freq=dataset.metadata.freq,\n",
    "    scaling=True,\n",
    "    dequantize=True,\n",
    "    flow_type='MAF',\n",
    "    n_blocks=2,\n",
    "    trainer=Trainer(device=device,\n",
    "                    epochs=40,\n",
    "                    learning_rate=1e-08,\n",
    "                    num_batches_per_epoch=100,\n",
    "                    batch_size=64)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = estimator.train(dataset_train, num_workers= 4)\n",
    "forecast_it, ts_it = make_evaluation_predictions(dataset=dataset_test,\n",
    "                                             predictor=predictor,\n",
    "                                             num_samples=100)\n",
    "forecasts = list(forecast_it)\n",
    "targets = list(ts_it)\n",
    "\n",
    "agg_metric, _ = evaluator(targets, forecasts, num_series=len(dataset_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_nll = 0.0\n",
    "count = 0\n",
    "\n",
    "for forecast, target in zip(forecasts, targets):\n",
    "    # Compute mean and std from the forecast samples\n",
    "    mu = forecast.samples.mean(axis=0)  # Mean of the samples\n",
    "    sigma = forecast.samples.std(axis=0)  # Standard deviation of the samples\n",
    "\n",
    "    # Align target to match the forecast's prediction length\n",
    "    target = np.array(target[-forecast.samples.shape[1]:])  # Take the last `prediction_length` values\n",
    "\n",
    "    if target.shape != mu.shape:\n",
    "        print(f\"Shape mismatch after alignment: target {target.shape}, forecast {mu.shape}\")\n",
    "        continue\n",
    "\n",
    "    # Compute NLL for this time series\n",
    "    nll = -torch.distributions.Normal(\n",
    "        torch.tensor(mu), torch.tensor(sigma)\n",
    "    ).log_prob(torch.tensor(target)).sum().item()\n",
    "\n",
    "    total_nll += nll\n",
    "    count += target.size  # Number of data points\n",
    "\n",
    "# Compute mean NLL\n",
    "if count > 0:\n",
    "    mean_nll = total_nll / count\n",
    "    print(f\"Mean NLL on Test Set: {mean_nll}\")\n",
    "else:\n",
    "    print(\"No valid data points for NLL calculation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CRPS: {}\".format(agg_metric['mean_wQuantileLoss']))\n",
    "print(\"ND: {}\".format(agg_metric['ND']))\n",
    "print(\"NRMSE: {}\".format(agg_metric['NRMSE']))\n",
    "print(\"MSE: {}\".format(agg_metric['MSE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CRPS-Sum: {}\".format(agg_metric['m_sum_mean_wQuantileLoss']))\n",
    "print(\"ND-Sum: {}\".format(agg_metric['m_sum_ND']))\n",
    "print(\"NRMSE-Sum: {}\".format(agg_metric['m_sum_NRMSE']))\n",
    "print(\"MSE-Sum: {}\".format(agg_metric['m_sum_MSE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAF_DONE##########################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Transformer-MAF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TransformerTempFlowEstimator(\n",
    "    d_model=16,\n",
    "    num_heads=4,\n",
    "    input_size=28,\n",
    "    target_dim=int(dataset.metadata.feat_static_cat[0].cardinality),\n",
    "    prediction_length=dataset.metadata.prediction_length,\n",
    "    context_length=dataset.metadata.prediction_length*4,\n",
    "    flow_type='MAF',\n",
    "    dequantize=True,\n",
    "    freq=dataset.metadata.freq,\n",
    "    trainer=Trainer(\n",
    "        device=device,\n",
    "        epochs=40,\n",
    "        learning_rate=1e-05,\n",
    "        num_batches_per_epoch=100,\n",
    "        batch_size=64,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = estimator.train(dataset_train, num_workers= 4)\n",
    "forecast_it, ts_it = make_evaluation_predictions(dataset=dataset_test,\n",
    "                                             predictor=predictor,\n",
    "                                             num_samples=100)\n",
    "forecasts = list(forecast_it)\n",
    "targets = list(ts_it)\n",
    "\n",
    "agg_metric, _ = evaluator(targets, forecasts, num_series=len(dataset_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_nll = 0.0\n",
    "count = 0\n",
    "\n",
    "for forecast, target in zip(forecasts, targets):\n",
    "    # Compute mean and std from the forecast samples\n",
    "    mu = forecast.samples.mean(axis=0)  # Mean of the samples\n",
    "    sigma = forecast.samples.std(axis=0)  # Standard deviation of the samples\n",
    "\n",
    "    # Align target to match the forecast's prediction length\n",
    "    target = np.array(target[-forecast.samples.shape[1]:])  # Take the last `prediction_length` values\n",
    "\n",
    "    if target.shape != mu.shape:\n",
    "        print(f\"Shape mismatch after alignment: target {target.shape}, forecast {mu.shape}\")\n",
    "        continue\n",
    "\n",
    "    # Compute NLL for this time series\n",
    "    nll = -torch.distributions.Normal(\n",
    "        torch.tensor(mu), torch.tensor(sigma)\n",
    "    ).log_prob(torch.tensor(target)).sum().item()\n",
    "\n",
    "    total_nll += nll\n",
    "    count += target.size  # Number of data points\n",
    "\n",
    "# Compute mean NLL\n",
    "if count > 0:\n",
    "    mean_nll = total_nll / count\n",
    "    print(f\"Mean NLL on Test Set: {mean_nll}\")\n",
    "else:\n",
    "    print(\"No valid data points for NLL calculation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CRPS: {}\".format(agg_metric['mean_wQuantileLoss']))\n",
    "print(\"ND: {}\".format(agg_metric['ND']))\n",
    "print(\"NRMSE: {}\".format(agg_metric['NRMSE']))\n",
    "print(\"MSE: {}\".format(agg_metric['MSE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CRPS-Sum: {}\".format(agg_metric['m_sum_mean_wQuantileLoss']))\n",
    "print(\"ND-Sum: {}\".format(agg_metric['m_sum_ND']))\n",
    "print(\"NRMSE-Sum: {}\".format(agg_metric['m_sum_NRMSE']))\n",
    "print(\"MSE-Sum: {}\".format(agg_metric['m_sum_MSE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TRANSFOMER_MAF_DONE##########################\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
