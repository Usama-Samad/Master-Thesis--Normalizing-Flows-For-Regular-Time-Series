{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f5db5ba-71b8-47ba-9fc8-49cf91cf1826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd4093f5-76df-4033-9d7d-0147c6b5d0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import sys\n",
    "import pts.dataset\n",
    "#sys.path.append(r'C:\\Users\\usama\\Desktop\\Thesis\\pytorch-ts-master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da677a08-1e15-4438-8dce-0a00c59b1d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notes Regarding versions:\n",
    "#3.6.13 python --> 3.8.10\n",
    "#0.10.0 gluonts --> 0.9.0\n",
    "#Version: 1.1.5 pandas --> 1.5.3\n",
    "#Version: 1.8.0 torch --> 2.1.5 --> 1.10.0 last version according to the issue answer in git\n",
    "#Version: 1.19.5 numpy --> 1.23.5\n",
    "#after this had issue regarding the distribution output importing changed the importing in the pts/dis_output line 34 to gluonts.torch.modules.distribution_output\n",
    "# and remove it from the importing cell.\n",
    "#encountered prefetch error handled it by downgrading torch version\n",
    "#to install gluonts 0.9.0 had to downgrade pip version to 24.0\n",
    "#!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40fd8239-f091-4bff-8d98-16d827813880",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # If using multi-GPU.\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set your desired seed\n",
    "set_seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76a518ce-2371-4371-9883-00d7998e3b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.dataset.multivariate_grouper import MultivariateGrouper\n",
    "#import gluonts.torch.distributions.distribution_output\n",
    "from gluonts.dataset.repository.datasets import dataset_recipes, get_dataset\n",
    "from pts.model.tempflow import TempFlowEstimator\n",
    "from pts.model.transformer_tempflow import TransformerTempFlowEstimator\n",
    "from pts import Trainer\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.evaluation import MultivariateEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc874844-c6c8-4b7e-9999-a2bcaea187e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef0292a-838d-48ac-b15d-aa6113f345e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset(\"taxi_30min\", regenerate=False)\n",
    "dataset.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea087765-bce5-4675-b7ee-c6aea210151e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_grouper = MultivariateGrouper(max_target_dim=int(dataset.metadata.feat_static_cat[0].cardinality))\n",
    "test_grouper = MultivariateGrouper(num_test_dates=int(len(dataset.test)/len(dataset.train)), \n",
    "                                    max_target_dim=int(dataset.metadata.feat_static_cat[0].cardinality))\n",
    "# val_grouper = MultivariateGrouper(max_target_dim=int(dataset.metadata.feat_static_cat[0].cardinality))\n",
    "# test_grouper = MultivariateGrouper(num_test_dates=int(len(dataset.test)/len(train_data)), \n",
    "#                                    max_target_dim=int(dataset.metadata.feat_static_cat[0].cardinality))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b32fcba-9be3-4cc3-9cdd-bae2b1375a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_train = train_grouper(train_dataset)\n",
    "dataset_train = train_grouper(dataset.train)\n",
    "dataset_test = test_grouper(dataset.test)\n",
    "# dataset_val = val_grouper(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c094beb-2cf9-4a67-91c5-e291af9a9553",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MultivariateEvaluator(quantiles=(np.arange(20)/20.0)[1:],\n",
    "                                  target_agg_funcs={'sum': np.sum})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbb4120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.evaluation import MultivariateEvaluator\n",
    "\n",
    "# Define the grid for hyperparameter tuning\n",
    "learning_rates = [1e-5, 1e-4, 1e-3, 1e-2]  # Example learning rates\n",
    "n_blocks_list = [2, 3, 4, 5, 6]  # Number of blocks to try\n",
    "\n",
    "# Initialize variables to store the best results\n",
    "best_metric = float('inf')  # Smallest CRPS-Sum\n",
    "best_params = None\n",
    "\n",
    "# Multivariate evaluator for evaluation\n",
    "evaluator = MultivariateEvaluator(\n",
    "    quantiles=(np.arange(20) / 20.0)[1:], target_agg_funcs={'sum': np.sum}\n",
    ")\n",
    "\n",
    "# Iterate over all combinations of hyperparameters\n",
    "for learning_rate in learning_rates:\n",
    "    for n_blocks in n_blocks_list:\n",
    "        print(f\"Trying learning_rate={learning_rate}, n_blocks={n_blocks}\")\n",
    "        \n",
    "        # Define the estimator\n",
    "        estimator = TempFlowEstimator(\n",
    "            target_dim=int(dataset.metadata.feat_static_cat[0].cardinality),\n",
    "            prediction_length=dataset.metadata.prediction_length,\n",
    "            cell_type='GRU',\n",
    "            input_size=7290,\n",
    "            freq=dataset.metadata.freq,\n",
    "            scaling=True,\n",
    "            dequantize=True,\n",
    "            flow_type='MAF',\n",
    "            n_blocks=n_blocks,\n",
    "            trainer=Trainer(\n",
    "                device=device,\n",
    "                epochs=40,\n",
    "                learning_rate=learning_rate,\n",
    "                num_batches_per_epoch=100,\n",
    "                batch_size=64,\n",
    "            ),\n",
    "        )\n",
    "        \n",
    "        # Train and evaluate the model\n",
    "        predictor = estimator.train(dataset_train, num_workers=4)\n",
    "        forecast_it, ts_it = make_evaluation_predictions(\n",
    "            dataset=dataset_test, predictor=predictor, num_samples=100\n",
    "        )\n",
    "        forecasts = list(forecast_it)\n",
    "        targets = list(ts_it)\n",
    "        \n",
    "        # Evaluate the forecasts\n",
    "        agg_metric, _ = evaluator(targets, forecasts, num_series=len(dataset_test))\n",
    "        current_metric = agg_metric['m_sum_mean_wQuantileLoss']\n",
    "        \n",
    "        print(f\"CRPS-Sum for learning_rate={learning_rate}, n_blocks={n_blocks}: {current_metric}\")\n",
    "        \n",
    "        # Update the best parameters if the current metric is better\n",
    "        if current_metric < best_metric:\n",
    "            best_metric = current_metric\n",
    "            best_params = {\n",
    "                'learning_rate': learning_rate,\n",
    "                'n_blocks': n_blocks,\n",
    "            }\n",
    "\n",
    "# Print the best results\n",
    "print(f\"Best CRPS-Sum: {best_metric}\")\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d6a063",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
