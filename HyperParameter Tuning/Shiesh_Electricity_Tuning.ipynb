{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f5db5ba-71b8-47ba-9fc8-49cf91cf1826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd4093f5-76df-4033-9d7d-0147c6b5d0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import sys\n",
    "import pts.dataset\n",
    "#sys.path.append(r'C:\\Users\\usama\\Desktop\\Thesis\\pytorch-ts-master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da677a08-1e15-4438-8dce-0a00c59b1d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notes Regarding versions:\n",
    "#3.6.13 python --> 3.8.10\n",
    "#0.10.0 gluonts --> 0.9.0\n",
    "#Version: 1.1.5 pandas --> 1.5.3\n",
    "#Version: 1.8.0 torch --> 2.1.5 --> 1.10.0 last version according to the issue answer in git\n",
    "#Version: 1.19.5 numpy --> 1.23.5\n",
    "#after this had issue regarding the distribution output importing changed the importing in the pts/dis_output line 34 to gluonts.torch.modules.distribution_output\n",
    "# and remove it from the importing cell.\n",
    "#encountered prefetch error handled it by downgrading torch version\n",
    "#to install gluonts 0.9.0 had to downgrade pip version to 24.0\n",
    "#!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40fd8239-f091-4bff-8d98-16d827813880",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # If using multi-GPU.\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set your desired seed\n",
    "set_seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76a518ce-2371-4371-9883-00d7998e3b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.dataset.multivariate_grouper import MultivariateGrouper\n",
    "#import gluonts.torch.distributions.distribution_output\n",
    "from gluonts.dataset.repository.datasets import dataset_recipes, get_dataset\n",
    "from pts.model.tempflow import TempFlowEstimator\n",
    "from pts.model.transformer_tempflow import TransformerTempFlowEstimator\n",
    "from pts import Trainer\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.evaluation import MultivariateEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc874844-c6c8-4b7e-9999-a2bcaea187e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aef0292a-838d-48ac-b15d-aa6113f345e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MetaData(freq='H', target=None, feat_static_cat=[CategoricalFeatureInfo(name='feat_static_cat_0', cardinality='137')], feat_static_real=[], feat_dynamic_real=[], feat_dynamic_cat=[], prediction_length=24)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = get_dataset(\"solar_nips\", regenerate=False)\n",
    "dataset.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea087765-bce5-4675-b7ee-c6aea210151e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_grouper = MultivariateGrouper(max_target_dim=int(dataset.metadata.feat_static_cat[0].cardinality))\n",
    "test_grouper = MultivariateGrouper(num_test_dates=int(len(dataset.test)/len(dataset.train)), \n",
    "                                    max_target_dim=int(dataset.metadata.feat_static_cat[0].cardinality))\n",
    "# val_grouper = MultivariateGrouper(max_target_dim=int(dataset.metadata.feat_static_cat[0].cardinality))\n",
    "# test_grouper = MultivariateGrouper(num_test_dates=int(len(dataset.test)/len(train_data)), \n",
    "#                                    max_target_dim=int(dataset.metadata.feat_static_cat[0].cardinality))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b32fcba-9be3-4cc3-9cdd-bae2b1375a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_train = train_grouper(train_dataset)\n",
    "dataset_train = train_grouper(dataset.train)\n",
    "dataset_test = test_grouper(dataset.test)\n",
    "# dataset_val = val_grouper(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c094beb-2cf9-4a67-91c5-e291af9a9553",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MultivariateEvaluator(quantiles=(np.arange(20)/20.0)[1:],\n",
    "                                  target_agg_funcs={'sum': np.sum})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fbb4120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying learning_rate=1e-05, n_blocks=2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5bb948bd91547f3a22740d862a3afc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3072x552 and 1484x40)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 43\u001b[0m\n\u001b[1;32m     24\u001b[0m estimator \u001b[38;5;241m=\u001b[39m TempFlowEstimator(\n\u001b[1;32m     25\u001b[0m     target_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(dataset\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mfeat_static_cat[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcardinality),\n\u001b[1;32m     26\u001b[0m     prediction_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m     ),\n\u001b[1;32m     40\u001b[0m )\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Train and evaluate the model\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m predictor \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m forecast_it, ts_it \u001b[38;5;241m=\u001b[39m make_evaluation_predictions(\n\u001b[1;32m     45\u001b[0m     dataset\u001b[38;5;241m=\u001b[39mdataset_test, predictor\u001b[38;5;241m=\u001b[39mpredictor, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     46\u001b[0m )\n\u001b[1;32m     47\u001b[0m forecasts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(forecast_it)\n",
      "File \u001b[0;32m~/Thesis/Thesis/pytorch-ts-master/pts/model/estimator.py:183\u001b[0m, in \u001b[0;36mPyTorchEstimator.train\u001b[0;34m(self, training_data, validation_data, num_workers, prefetch_factor, shuffle_buffer_length, cache_data, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    173\u001b[0m     training_data: Dataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    182\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PyTorchPredictor:\n\u001b[0;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprefetch_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefetch_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle_buffer_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle_buffer_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpredictor\n",
      "File \u001b[0;32m~/Thesis/Thesis/pytorch-ts-master/pts/model/estimator.py:153\u001b[0m, in \u001b[0;36mPyTorchEstimator.train_model\u001b[0;34m(self, training_data, validation_data, num_workers, prefetch_factor, shuffle_buffer_length, cache_data, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m     validation_iter_dataset \u001b[38;5;241m=\u001b[39m TransformedIterableDataset(\n\u001b[1;32m    136\u001b[0m         dataset\u001b[38;5;241m=\u001b[39mvalidation_data,\n\u001b[1;32m    137\u001b[0m         transform\u001b[38;5;241m=\u001b[39mtransformation\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m         cache_data\u001b[38;5;241m=\u001b[39mcache_data,\n\u001b[1;32m    142\u001b[0m     )\n\u001b[1;32m    143\u001b[0m     validation_data_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[1;32m    144\u001b[0m         validation_iter_dataset,\n\u001b[1;32m    145\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrained_net\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_data_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m TrainOutput(\n\u001b[1;32m    160\u001b[0m     transformation\u001b[38;5;241m=\u001b[39mtransformation,\n\u001b[1;32m    161\u001b[0m     trained_net\u001b[38;5;241m=\u001b[39mtrained_net,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    164\u001b[0m     ),\n\u001b[1;32m    165\u001b[0m )\n",
      "File \u001b[0;32m~/Thesis/Thesis/pytorch-ts-master/pts/trainer.py:69\u001b[0m, in \u001b[0;36mTrainer.__call__\u001b[0;34m(self, net, train_iter, validation_iter)\u001b[0m\n\u001b[1;32m     66\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     68\u001b[0m inputs \u001b[38;5;241m=\u001b[39m [v\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m data_entry\u001b[38;5;241m.\u001b[39mvalues()]\n\u001b[0;32m---> 69\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m     72\u001b[0m     loss \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Thesis/Thesis/pytorch-ts-master/pts/model/tempflow/tempflow_network.py:372\u001b[0m, in \u001b[0;36mTempFlowTrainingNetwork.forward\u001b[0;34m(self, target_dimension_indicator, past_time_feat, past_target_cdf, past_observed_values, past_is_pad, future_time_feat, future_target_cdf, future_observed_values)\u001b[0m\n\u001b[1;32m    368\u001b[0m seq_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_length \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_length\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# unroll the decoder in \"training mode\", i.e. by providing future data\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# as well\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m rnn_outputs, _, scale, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munroll_encoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_time_feat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_time_feat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_target_cdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_target_cdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_observed_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_observed_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_is_pad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_is_pad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfuture_time_feat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_time_feat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfuture_target_cdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_target_cdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_dimension_indicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_dimension_indicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# put together target sequence\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;66;03m# (batch_size, seq_len, target_dim)\u001b[39;00m\n\u001b[1;32m    384\u001b[0m target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m    385\u001b[0m     (past_target_cdf[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_length :, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m], future_target_cdf),\n\u001b[1;32m    386\u001b[0m     dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    387\u001b[0m )\n",
      "File \u001b[0;32m~/Thesis/Thesis/pytorch-ts-master/pts/model/tempflow/tempflow_network.py:279\u001b[0m, in \u001b[0;36mTempFlowTrainingNetwork.unroll_encoder\u001b[0;34m(self, past_time_feat, past_target_cdf, past_observed_values, past_is_pad, future_time_feat, future_target_cdf, target_dimension_indicator)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# scale is computed on the context length last units of the past target\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;66;03m# scale shape is (batch_size, 1, target_dim)\u001b[39;00m\n\u001b[1;32m    274\u001b[0m _, scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler(\n\u001b[1;32m    275\u001b[0m     past_target_cdf[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_length :, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m],\n\u001b[1;32m    276\u001b[0m     past_observed_values[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_length :, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m],\n\u001b[1;32m    277\u001b[0m )\n\u001b[0;32m--> 279\u001b[0m outputs, states, lags_scaled, inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munroll\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_feat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_feat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_dimension_indicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_dimension_indicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43munroll_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubsequences_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs, states, scale, lags_scaled, inputs\n",
      "File \u001b[0;32m~/Thesis/Thesis/pytorch-ts-master/pts/model/tempflow/tempflow_network.py:175\u001b[0m, in \u001b[0;36mTempFlowTrainingNetwork.unroll\u001b[0;34m(self, lags, scale, time_feat, target_dimension_indicator, unroll_length, begin_state)\u001b[0m\n\u001b[1;32m    170\u001b[0m inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((input_lags, repeated_index_embeddings, time_feat), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m#Shape of Inputs torch.Size([64, 48, 552])\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m#print(\"inputs\")\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# unroll encoder\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m#outputs, state = self.rnn(inputs, begin_state) #Shape of Outputs torch.Size([64, 48, 40])\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m#print(\"im here linear not working\")\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;66;03m#print(outputs)\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# assert_shape(outputs, (-1, unroll_length, self.num_cells))\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# for s in state:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m#     lags_scaled, (-1, unroll_length, self.target_dim, len(self.lags_seq)),\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs, outputs, lags_scaled, inputs\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3072x552 and 1484x40)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.evaluation import MultivariateEvaluator\n",
    "\n",
    "# Define the grid for hyperparameter tuning\n",
    "learning_rates = [1e-5, 1e-4, 1e-3, 1e-2]  # Example learning rates\n",
    "n_blocks_list = [2, 3, 4, 5, 6]  # Number of blocks to try\n",
    "\n",
    "# Initialize variables to store the best results\n",
    "best_metric = float('inf')  # Smallest CRPS-Sum\n",
    "best_params = None\n",
    "\n",
    "# Multivariate evaluator for evaluation\n",
    "evaluator = MultivariateEvaluator(\n",
    "    quantiles=(np.arange(20) / 20.0)[1:], target_agg_funcs={'sum': np.sum}\n",
    ")\n",
    "\n",
    "# Iterate over all combinations of hyperparameters\n",
    "for learning_rate in learning_rates:\n",
    "    for n_blocks in n_blocks_list:\n",
    "        print(f\"Trying learning_rate={learning_rate}, n_blocks={n_blocks}\")\n",
    "        \n",
    "        # Define the estimator\n",
    "        estimator = TempFlowEstimator(\n",
    "            target_dim=int(dataset.metadata.feat_static_cat[0].cardinality),\n",
    "            prediction_length=24,\n",
    "            cell_type='GRU',\n",
    "            input_size=552,\n",
    "            freq=dataset.metadata.freq,\n",
    "            scaling=True,\n",
    "            dequantize=True,\n",
    "            n_blocks=n_blocks,\n",
    "            trainer=Trainer(\n",
    "                device=device,\n",
    "                epochs=1,\n",
    "                learning_rate=learning_rate,\n",
    "                num_batches_per_epoch=100,\n",
    "                batch_size=64,\n",
    "            ),\n",
    "        )\n",
    "        \n",
    "        # Train and evaluate the model\n",
    "        predictor = estimator.train(dataset_train, num_workers=4)\n",
    "        forecast_it, ts_it = make_evaluation_predictions(\n",
    "            dataset=dataset_test, predictor=predictor, num_samples=100\n",
    "        )\n",
    "        forecasts = list(forecast_it)\n",
    "        targets = list(ts_it)\n",
    "        \n",
    "        # Evaluate the forecasts\n",
    "        agg_metric, _ = evaluator(targets, forecasts, num_series=len(dataset_test))\n",
    "        current_metric = agg_metric['m_sum_mean_wQuantileLoss']\n",
    "        \n",
    "        print(f\"CRPS-Sum for learning_rate={learning_rate}, n_blocks={n_blocks}: {current_metric}\")\n",
    "        \n",
    "        # Update the best parameters if the current metric is better\n",
    "        if current_metric < best_metric:\n",
    "            best_metric = current_metric\n",
    "            best_params = {\n",
    "                'learning_rate': learning_rate,\n",
    "                'n_blocks': n_blocks,\n",
    "            }\n",
    "\n",
    "# Print the best results\n",
    "print(f\"Best CRPS-Sum: {best_metric}\")\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d6a063",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
